# lstm.py
import torch
import torch.nn as nn
import numpy as np
import pickle
import time

# === æ¨¡å‹å®šä¹‰ ===
class DualLSTMModel(nn.Module):
    def __init__(self, input_size=2, hidden_size=128, num_layers=2, note_vocab=128, dur_vocab=256):
        super(DualLSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.dropout = nn.Dropout(0.3)
        self.fc_note = nn.Linear(hidden_size, note_vocab)
        self.fc_dur = nn.Linear(hidden_size, dur_vocab)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.dropout(out[:, -1, :])
        note_out = self.fc_note(out)
        dur_out = self.fc_dur(out)
        return note_out, dur_out

# === å…¨å±€å˜é‡ ===
model = None
int_to_note = {}
int_to_dur = {}
note_to_int = {}
dur_to_int = {}
note_vocab = 0
dur_vocab = 0
SEQUENCE_LENGTH = 50
generated_melody = []
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === åŠ è½½æ¨¡å‹å’Œæ˜ å°„ ===
def load_lstm_model(
    model_path="lstm_model.pth",
    note_path="data/notes.pkl",
    dur_path="data/durations.pkl"
):
    global model, int_to_note, int_to_dur, note_to_int, dur_to_int, note_vocab, dur_vocab

    with open(note_path, "rb") as f:
        int_to_note = pickle.load(f)
    note_to_int = {v: k for k, v in int_to_note.items()}
    note_vocab = len(note_to_int)

    with open(dur_path, "rb") as f:
        int_to_dur = pickle.load(f)
    dur_to_int = {v: k for k, v in int_to_dur.items()}
    dur_vocab = len(dur_to_int)

    model_obj = DualLSTMModel(input_size=2, note_vocab=note_vocab, dur_vocab=dur_vocab)
    model_obj.load_state_dict(torch.load(model_path, map_location=device))
    model_obj.to(device)
    model_obj.eval()
    model = model_obj
    print("âœ… LSTM æ¨¡å‹åŠ è½½å®Œæˆ")

# === ç”Ÿæˆæ—‹å¾‹ï¼ˆè‡ªåŠ¨æ‰©å±•è‡³è‡³å°‘40ç§’ï¼‰ ===
def generate_lstm_melody(seed_notes, seed_durations, min_duration=40.0, temperature=1.2):
    global generated_melody

    if model is None:
        print("âŒ æ¨¡å‹æœªåŠ è½½")
        return []

    # æ‰©å±•ç§å­åºåˆ—
    while len(seed_notes) < SEQUENCE_LENGTH:
        seed_notes += seed_notes
        seed_durations += seed_durations
    seed_notes = seed_notes[:SEQUENCE_LENGTH]
    seed_durations = seed_durations[:SEQUENCE_LENGTH]

    melody = []
    total_time = 0.0
    MIN_PITCH = 48  # C3ï¼Œå±è”½ä½éŸ³

    while total_time < min_duration:
        # æ„å»ºè¾“å…¥åºåˆ— [note/128.0, dur/1000.0]
        input_seq = [[n / 128.0, d / 1000.0] for n, d in zip(seed_notes, seed_durations)]
        input_tensor = torch.tensor([input_seq], dtype=torch.float32).to(device)

        with torch.no_grad():
            note_pred, dur_pred = model(input_tensor)

            # é‡‡æ ·å‰å±è”½ä½éŸ³æ¦‚ç‡ï¼ˆæ–¹æ³•2ï¼‰
            note_probs = torch.softmax(note_pred / temperature, dim=1)
            note_probs[0, :MIN_PITCH] = 0
            note_probs = note_probs / note_probs.sum()

            dur_probs = torch.softmax(dur_pred / temperature, dim=1)

            note_index = torch.multinomial(note_probs, num_samples=1).item()
            dur_index = torch.multinomial(dur_probs, num_samples=1).item()

            pred_note = int(int_to_note[note_index])

            # å¼ºåˆ¶ä¸‹é™éŸ³é«˜ï¼ˆæ–¹æ³•1ï¼‰
            if pred_note < MIN_PITCH:
                pred_note = MIN_PITCH

            pred_dur_ms = int(int_to_dur[dur_index])
            scaled_duration = max(pred_dur_ms * 2 / 1000.0, 0.2)

            melody.append((pred_note, scaled_duration))
            total_time += scaled_duration

        # æ›´æ–°ç§å­
        seed_notes.append(note_index)
        seed_durations.append(dur_index)
        seed_notes = seed_notes[1:]
        seed_durations = seed_durations[1:]

    print(f"ğŸ¼ LSTM ç”Ÿæˆæ—‹å¾‹ï¼ˆæ€»æ—¶é•¿ {total_time:.2f} ç§’ï¼‰")
    generated_melody = melody
    return melody

# === è·å–æ—‹å¾‹ ===
def get_generated_melody():
    return generated_melody

# === æ’­æ”¾æ—‹å¾‹ï¼ˆæœ€å¤š 20 ç§’ï¼‰ ===
def play_lstm_melody(event_handler):
    melody = get_generated_melody()
    if not melody:
        print("âŒ æ²¡æœ‰ç”Ÿæˆçš„ LSTM æ—‹å¾‹")
        return

    print("â–¶ï¸ æ’­æ”¾ LSTM æ—‹å¾‹ï¼ˆæœ€å¤š 20 ç§’ï¼‰...")
    start_time = time.time()

    for note, duration in melody:
        if time.time() - start_time > 20:
            print("â¹ æ’­æ”¾è¶…æ—¶è‡ªåŠ¨åœæ­¢ï¼ˆ20 ç§’ï¼‰")
            break
        event_handler.play_midi(note)
        time.sleep(duration)
        event_handler.stop_midi(note)
