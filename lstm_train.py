import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pickle
import os

# **æ£€æŸ¥ GPU**
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

if device == torch.device("cpu"):
    print("æ²¡æœ‰æ£€æµ‹åˆ°å¯ç”¨çš„ GPUï¼Œè®­ç»ƒç»ˆæ­¢ã€‚è¯·åœ¨ GPU è®¾å¤‡ä¸Šè¿è¡Œæ­¤ä»£ç ã€‚")
    exit(1)

print(f"è®­ç»ƒå°†åœ¨ {device} ä¸Šè¿›è¡Œ ")

# **è¶…å‚æ•°**
EPOCHS = 200  # è®­ç»ƒè½®æ•°
BATCH_SIZE = 64  # æ‰¹é‡å¤§å°
SEQUENCE_LENGTH = 100  # LSTM è¾“å…¥çš„åºåˆ—é•¿åº¦
LEARNING_RATE = 0.001  # å­¦ä¹ ç‡
DATASET_PATH = "dataset.txt"  # è®­ç»ƒæ•°æ®æ–‡ä»¶
MODEL_PATH = "lstm_model.pth"  # æ¨¡å‹ä¿å­˜è·¯å¾„
DATA_PATH = "data/"  # æ•°æ®å­˜å‚¨ç›®å½•


# **LSTM æ¨¡å‹**
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size=256, num_layers=3, output_size=128):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.dropout(out[:, -1, :])  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        out = self.fc(out)
        return out


# **è¯»å– dataset.txt**
def load_dataset():
    """ ä» dataset.txt è¯»å–éŸ³ç¬¦å’ŒæŒç»­æ—¶é—´ """
    notes, durations = [], []

    with open(DATASET_PATH, "r") as f:
        lines = f.readlines()

    for line in lines:
        pairs = line.strip().split(" ")
        for pair in pairs:
            try:
                note, duration = pair.split(":")
                notes.append(int(note))  # è½¬æ¢ä¸ºæ•´æ•°
                durations.append(int(duration))
            except ValueError:
                print(f"è·³è¿‡æ— æ•ˆæ•°æ®: {pair}")

    # **ä¿å­˜éŸ³ç¬¦æ˜ å°„**
    os.makedirs(DATA_PATH, exist_ok=True)
    with open(DATA_PATH + "notes.pkl", "wb") as f:
        pickle.dump(notes, f)

    return notes


# **æ•°æ®é›†å®šä¹‰**
class MusicDataset(Dataset):
    def __init__(self, sequences, targets):
        self.sequences = sequences
        self.targets = targets

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        return torch.tensor(self.sequences[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.long)


# **å‡†å¤‡æ•°æ®**
def prepare_sequences(notes):
    """ å°†éŸ³ç¬¦è½¬æ¢ä¸º LSTM å¯ç”¨çš„åºåˆ— """
    note_to_int = {note: number for number, note in enumerate(sorted(set(notes)))}
    sequences, targets = [], []

    for i in range(0, len(notes) - SEQUENCE_LENGTH):
        sequence_in = notes[i:i + SEQUENCE_LENGTH]
        sequence_out = notes[i + SEQUENCE_LENGTH]
        sequences.append([note_to_int[n] for n in sequence_in])
        targets.append(note_to_int[sequence_out])

    return np.array(sequences) / float(len(note_to_int)), np.array(targets), note_to_int


# **è®­ç»ƒæ¨¡å‹**
def train_network():
    """ è®­ç»ƒ LSTM ç½‘ç»œ """
    notes = load_dataset()
    sequences, targets, note_to_int = prepare_sequences(notes)
    dataset = MusicDataset(sequences, targets)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

    # **åˆ›å»º LSTM æ¨¡å‹**
    model = LSTMModel(input_size=1, output_size=len(note_to_int)).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # **è®­ç»ƒå¾ªç¯**
    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0
        for batch_x, batch_y in dataloader:
            batch_x, batch_y = batch_x.to(device), batch_y.to(device)
            batch_x = batch_x.unsqueeze(-1)  # **å¢åŠ æœ€åä¸€ç»´**

            optimizer.zero_grad()
            output = model(batch_x)
            loss = criterion(output, batch_y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch [{epoch + 1}/{EPOCHS}], Loss: {total_loss / len(dataloader):.4f}")

        # **ä¿å­˜æœ€ä¼˜æ¨¡å‹**
        if (epoch + 1) % 10 == 0:
            torch.save(model.state_dict(), f"weights-improvement-{epoch + 1}.pth")

    # **ä¿å­˜æœ€ç»ˆæ¨¡å‹**
    torch.save(model.state_dict(), MODEL_PATH)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜ï¼")


if __name__ == '__main__':
    train_network()
